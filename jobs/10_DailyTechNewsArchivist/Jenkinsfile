pipeline {
    agent any

    // 設定排程：每天早上 8 點自動執行 (Cron 語法)
    triggers {
        cron('0 8 * * *') 
    }

    options {
        // logRotator: 負責輪替日誌
        // numToKeepStr: '10' 代表只保留最新的 10 筆
        buildDiscarder(logRotator(numToKeepStr: '10'))
        
        // 讓 console log 加上時間戳記，可以順便加這行
        timestamps() 
    }

    stages {
        stage('1. Checkout') {
            steps {
                git branch: 'main', url: 'https://github.com/okm2629/jenkins.git'
            }
        }

        stage('2. Build Image') {
            steps {
                script {
                    dir('jobs/10_DailyTechNewsArchivist') {
                        // 這會讓容器直接使用 Jenkins 伺服器的網路，解決 DNS 解析問題
                        sh "docker build --network=host -t news-scraper:latest ."
                    }
                }
            }
        }

        stage('3. Run Scraper') {
            steps {
                script {
                    dir('jobs/10_DailyTechNewsArchivist') {

                        sh "docker run --rm --network=host -v \$(pwd):/app/data news-scraper:latest"
                        
                        // (除錯用) 加入這行確認檔案真的有產生
                        sh "ls -l *.csv" 
                    }
                }
            }
        }
        
        stage('4. Archive Results') {
            steps {
                dir('jobs/10_DailyTechNewsArchivist') {
                    // 使用通配符 *.* 抓取所有的 csv 和 html，這樣不管你檔名怎麼改都抓得到
                    archiveArtifacts artifacts: '*.*', fingerprint: true
                }
            }
        }
    }
}